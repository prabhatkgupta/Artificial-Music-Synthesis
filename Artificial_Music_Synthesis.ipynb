{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artificial Music Synthesis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIOe48ApZZoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from IPython import *\n",
        "from keras.models import *\n",
        "from keras.initializers import *\n",
        "from keras.utils import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from music21 import *\n",
        "from itertools import zip_longest\n",
        "import random\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahkj8cKdgZFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display.Audio('30s_trained_model.mp3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEfOM2jvrH_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __parse_midi(data_fn):\n",
        "    # Parse the MIDI data for separate melody and accompaniment parts.\n",
        "    midi_data = converter.parse(data_fn)\n",
        "    # Get melody part, compress into single voice.\n",
        "    melody_stream = midi_data[5]     # For Metheny piece, Melody is Part #5.\n",
        "    melody1, melody2 = melody_stream.getElementsByClass(stream.Voice)\n",
        "    for j in melody2:\n",
        "        melody1.insert(j.offset, j)\n",
        "    melody_voice = melody1\n",
        "\n",
        "    for i in melody_voice:\n",
        "        if i.quarterLength == 0.0:\n",
        "            i.quarterLength = 0.25\n",
        "\n",
        "    # Change key signature to adhere to comp_stream (1 sharp, mode = major).\n",
        "    # Also add Electric Guitar. \n",
        "    melody_voice.insert(0, instrument.ElectricGuitar())\n",
        "    melody_voice.insert(0, key.KeySignature(sharps=1))\n",
        "\n",
        "    # The accompaniment parts. Take only the best subset of parts from\n",
        "    # the original data. Maybe add more parts, hand-add valid instruments.\n",
        "    # Should add least add a string part (for sparse solos).\n",
        "    # Verified are good parts: 0, 1, 6, 7 '''\n",
        "    partIndices = [0, 1, 6, 7]\n",
        "    comp_stream = stream.Voice()\n",
        "    comp_stream.append([j.flat for i, j in enumerate(midi_data) \n",
        "        if i in partIndices])\n",
        "\n",
        "    # Full stream containing both the melody and the accompaniment. \n",
        "    # All parts are flattened. \n",
        "    full_stream = stream.Voice()\n",
        "    for i in range(len(comp_stream)):\n",
        "        full_stream.append(comp_stream[i])\n",
        "    full_stream.append(melody_voice)\n",
        "\n",
        "    # Extract solo stream, assuming you know the positions ..ByOffset(i, j).\n",
        "    # Note that for different instruments (with stream.flat), you NEED to use\n",
        "    # stream.Part(), not stream.Voice().\n",
        "    # Accompanied solo is in range [478, 548)\n",
        "    solo_stream = stream.Voice()\n",
        "    for part in full_stream:\n",
        "        curr_part = stream.Part()\n",
        "        curr_part.append(part.getElementsByClass(instrument.Instrument))\n",
        "        curr_part.append(part.getElementsByClass(tempo.MetronomeMark))\n",
        "        curr_part.append(part.getElementsByClass(key.KeySignature))\n",
        "        curr_part.append(part.getElementsByClass(meter.TimeSignature))\n",
        "        curr_part.append(part.getElementsByOffset(476, 548, \n",
        "                                                  includeEndBoundary=True))\n",
        "        cp = curr_part.flat\n",
        "        solo_stream.insert(cp)\n",
        "\n",
        "    # Group by measure so you can classify. \n",
        "    # Note that measure 0 is for the time signature, metronome, etc. which have\n",
        "    # an offset of 0.0.\n",
        "    melody_stream = solo_stream[-1]\n",
        "    measures = OrderedDict()\n",
        "    offsetTuples = [(int(n.offset / 4), n) for n in melody_stream]\n",
        "    measureNum = 0 # for now, don't use real m. nums (119, 120)\n",
        "    for key_x, group in groupby(offsetTuples, lambda x: x[0]):\n",
        "        measures[measureNum] = [n[1] for n in group]\n",
        "        measureNum += 1\n",
        "\n",
        "    # Get the stream of chords.\n",
        "    # offsetTuples_chords: group chords by measure number.\n",
        "    chordStream = solo_stream[0]\n",
        "    chordStream.removeByClass(note.Rest)\n",
        "    chordStream.removeByClass(note.Note)\n",
        "    offsetTuples_chords = [(int(n.offset / 4), n) for n in chordStream]\n",
        "\n",
        "    # Generate the chord structure. Use just track 1 (piano) since it is\n",
        "    # the only instrument that has chords. \n",
        "    # Group into 4s, just like before. \n",
        "    chords = OrderedDict()\n",
        "    measureNum = 0\n",
        "    for key_x, group in groupby(offsetTuples_chords, lambda x: x[0]):\n",
        "        chords[measureNum] = [n[1] for n in group]\n",
        "        measureNum += 1\n",
        "\n",
        "    # Fix for the below problem.\n",
        "    #   1) Find out why len(measures) != len(chords).\n",
        "    #   ANSWER: resolves at end but melody ends 1/16 before last measure so doesn't\n",
        "    #           actually show up, while the accompaniment's beat 1 right after does.\n",
        "    #           Actually on second thought: melody/comp start on Ab, and resolve to\n",
        "    #           the same key (Ab) so could actually just cut out last measure to loop.\n",
        "    #           Decided: just cut out the last measure. \n",
        "    del chords[len(chords) - 1]\n",
        "    assert len(chords) == len(measures)\n",
        "\n",
        "    return measures, chords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlTuhh16rKoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __get_abstract_grammars(measures, chords):\n",
        "    # extract grammars\n",
        "    abstract_grammars = []\n",
        "    for ix in range(1, len(measures)):\n",
        "        m = stream.Voice()\n",
        "        for i in measures[ix]:\n",
        "            m.insert(i.offset, i)\n",
        "        c = stream.Voice()\n",
        "        for j in chords[ix]:\n",
        "            c.insert(j.offset, j)\n",
        "        parsed = parse_melody(m, c)\n",
        "        abstract_grammars.append(parsed)\n",
        "\n",
        "    return abstract_grammars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf_V0pUbq4x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_musical_data(data_fn):\n",
        "    \n",
        "    measures, chords = __parse_midi(data_fn)\n",
        "    abstract_grammars = __get_abstract_grammars(measures, chords)\n",
        "\n",
        "    return chords, abstract_grammars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7mNdol4q-YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_corpus_data(abstract_grammars):\n",
        "    corpus = [x for sublist in abstract_grammars for x in sublist.split(' ')]\n",
        "    values = set(corpus)\n",
        "    val_indices = dict((v, i) for i, v in enumerate(values))\n",
        "    indices_val = dict((i, v) for i, v in enumerate(values))\n",
        "\n",
        "    return corpus, values, val_indices, indices_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HoXhP83scqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_processing(corpus, values_indices, m = 60, Tx = 30):\n",
        "    # cut the corpus into semi-redundant sequences of Tx values\n",
        "    Tx = Tx \n",
        "    N_values = len(set(corpus))\n",
        "    np.random.seed(0)\n",
        "    X = np.zeros((m, Tx, N_values), dtype=np.bool)\n",
        "    Y = np.zeros((m, Tx, N_values), dtype=np.bool)\n",
        "    for i in range(m):\n",
        "#         for t in range(1, Tx):\n",
        "        random_idx = np.random.choice(len(corpus) - Tx)\n",
        "        corp_data = corpus[random_idx:(random_idx + Tx)]\n",
        "        for j in range(Tx):\n",
        "            idx = values_indices[corp_data[j]]\n",
        "            if j != 0:\n",
        "                X[i, j, idx] = 1\n",
        "                Y[i, j-1, idx] = 1\n",
        "    \n",
        "    Y = np.swapaxes(Y,0,1)\n",
        "    Y = Y.tolist()\n",
        "    return np.asarray(X), np.asarray(Y), N_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL52ynGPmgOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Load_Data():\n",
        "    chords, abstract_grammars = get_musical_data('original_metheny.mid')\n",
        "    corpus, notes, notes_indices, indices_notes = get_corpus_data(abstract_grammars)\n",
        "    notes = len(set(corpus))\n",
        "    X_train, Y_train, notes = data_processing(corpus, notes_indices, 60, 30)   \n",
        "    return (X_train, Y_train, notes, indices_notes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vso2iNWdBAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reshapor = Reshape((1,78))\n",
        "LSTM_Cell = LSTM(64,return_state = True)\n",
        "dense = Dense(78,activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-CBiYuvs442",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train, notes, indices_notes = Load_Data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT7kna11tAXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('shape of X:', X_train.shape)\n",
        "print('number of training examples:', X_train.shape[0])\n",
        "print('Tx (length of sequence):', X_train.shape[1])\n",
        "print('total # of unique values:', notes)\n",
        "print('Shape of Y:', Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aIX-9uS-SpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(x):\n",
        "    x = K.argmax(x)\n",
        "    x = tf.one_hot(x, 78) \n",
        "    x = RepeatVector(1)(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfRaQhNjtMjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reshapor = Reshape((1,78))\n",
        "LSTM_cell = LSTM(64,return_state=True)\n",
        "Densor = Dense(78,activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on2efDxZtuc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Propagation(input_shape,tx):\n",
        "\n",
        "  X_input = Input(shape = input_shape)\n",
        "  X = X_input\n",
        "  a0 = Input(shape=(64,),name=\"a0\")\n",
        "  c0 = Input(shape=(64,),name=\"c0\")\n",
        "  a = a0\n",
        "  c = c0\n",
        "\n",
        "  outputs = []\n",
        "  for t in range(tx):\n",
        "    x = Lambda(lambda x: X[:,t,:])(X)\n",
        "    x = reshapor(x)\n",
        "    a,_,c = LSTM_cell(x,initial_state=[a,c])\n",
        "    output = Densor(a)\n",
        "    outputs.append(output)\n",
        "  \n",
        "  model = Model([X_input,a0,c0],outputs)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T4kpX_hwESB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Caller_Function():\n",
        "\n",
        "  X_train, Y_train, notes, indices_notes = Load_Data()\n",
        "  num_epochs = 1000\n",
        "  mini_batch_size = 10\n",
        "  shape = X_train.shape\n",
        "  input_shape = (shape[1],shape[2])\n",
        "  tx = shape[1]\n",
        "  m = shape[0]\n",
        "  a0 = np.zeros((m, 64))\n",
        "  c0 = np.zeros((m, 64))\n",
        "\n",
        "  model = Propagation(input_shape,tx)\n",
        "  opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "  model.fit([X_train,a0,c0],list(Y_train),epochs=num_epochs)\n",
        "  #model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0XNYImKx8Bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Caller_Function()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve8FyD4V0bQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Music_Generation_Helper(notes):\n",
        "\n",
        "  X_input = Input((1,notes))\n",
        "  a0 = Input((64,),name=\"a0\")\n",
        "  c0 = Input((64,),name=\"c0\")\n",
        "  a = a0\n",
        "  c = c0\n",
        "  X = X_input \n",
        "\n",
        "  outputs = []\n",
        "  for t in range(20):\n",
        "\n",
        "    a,_,c = LSTM_Cell(X,initial_state = [a,c])\n",
        "    output = Densor(a)\n",
        "    outputs.append(output)\n",
        "    X = Lambda(one_hot)(output)\n",
        "\n",
        "  model = Model([X_input,a0,c0],outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-_liEKhD1rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_and_sample(inference_model):\n",
        "\n",
        "  x = np.zeros((1,1,78))\n",
        "  a0 = np.zeros((1,64))\n",
        "  c0 = np.zeros((1,64))\n",
        "\n",
        "  output = inference_model.predict([x,a0,c0])\n",
        "  indices = np.argmax(output,2)\n",
        "  result = to_categorical(indices)\n",
        "\n",
        "  return result, indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxuSfp-lGKKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __roundDown(num, mult):\n",
        "    return (float(num) - (float(num) % mult))\n",
        "\n",
        "def __roundUp(num, mult):\n",
        "    return __roundDown(num, mult) + mult\n",
        "\n",
        "def __roundUpDown(num, mult, upDown):\n",
        "    if upDown < 0:\n",
        "        return __roundDown(num, mult)\n",
        "    else:\n",
        "        return __roundUp(num, mult)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHdKCZcYG_Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __is_scale_tone(chord, note):\n",
        "    # Method: generate all scales that have the chord notes th check if note is\n",
        "    # in names\n",
        "\n",
        "    # Derive major or minor scales (minor if 'other') based on the quality\n",
        "    # of the chord.\n",
        "    scaleType = scale.DorianScale() # i.e. minor pentatonic\n",
        "    if chord.quality == 'major':\n",
        "        scaleType = scale.MajorScale()\n",
        "    # Can change later to deriveAll() for flexibility. If so then use list\n",
        "    # comprehension of form [x for a in b for x in a].\n",
        "    scales = scaleType.derive(chord) # use deriveAll() later for flexibility\n",
        "    allPitches = list(set([pitch for pitch in scales.getPitches()]))\n",
        "    allNoteNames = [i.name for i in allPitches] # octaves don't matter\n",
        "\n",
        "    # Get note name. Return true if in the list of note names.\n",
        "    noteName = note.name\n",
        "    return (noteName in allNoteNames)\n",
        "\n",
        "def __is_approach_tone(chord, note):\n",
        "    # Method: see if note is +/- 1 a chord tone.\n",
        "\n",
        "    for chordPitch in chord.pitches:\n",
        "        stepUp = chordPitch.transpose(1)\n",
        "        stepDown = chordPitch.transpose(-1)\n",
        "        if (note.name == stepDown.name or \n",
        "            note.name == stepDown.getEnharmonic().name or\n",
        "            note.name == stepUp.name or\n",
        "            note.name == stepUp.getEnharmonic().name):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def __is_chord_tone(lastChord, note):\n",
        "    return (note.name in (p.name for p in lastChord.pitches))\n",
        "\n",
        "def __generate_chord_tone(lastChord):\n",
        "    lastChordNoteNames = [p.nameWithOctave for p in lastChord.pitches]\n",
        "    return note.Note(random.choice(lastChordNoteNames))\n",
        "\n",
        "def __generate_scale_tone(lastChord):\n",
        "    # Derive major or minor scales (minor if 'other') based on the quality\n",
        "    # of the lastChord.\n",
        "    scaleType = scale.WeightedHexatonicBlues() # minor pentatonic\n",
        "    if lastChord.quality == 'major':\n",
        "        scaleType = scale.MajorScale()\n",
        "   \n",
        "    scales = scaleType.derive(lastChord) # use deriveAll() later for flexibility\n",
        "    allPitches = list(set([pitch for pitch in scales.getPitches()]))\n",
        "    allNoteNames = [i.name for i in allPitches] # octaves don't matter\n",
        "\n",
        "    # Return a note (no octave here) in a scale that matches the lastChord.\n",
        "    sNoteName = random.choice(allNoteNames)\n",
        "    lastChordSort = lastChord.sortAscending()\n",
        "    sNoteOctave = random.choice([i.octave for i in lastChordSort.pitches])\n",
        "    sNote = note.Note((\"%s%s\" % (sNoteName, sNoteOctave)))\n",
        "    return sNote\n",
        "\n",
        "def __generate_approach_tone(lastChord):\n",
        "    sNote = __generate_scale_tone(lastChord)\n",
        "    aNote = sNote.transpose(random.choice([1, -1]))\n",
        "    return aNote\n",
        "\n",
        "def __generate_arbitrary_tone(lastChord):\n",
        "    return __generate_scale_tone(lastChord) # fix later, make random note.\n",
        "\n",
        "def parse_melody(fullMeasureNotes, fullMeasureChords):\n",
        "    # Remove extraneous elements.x\n",
        "    measure = copy.deepcopy(fullMeasureNotes)\n",
        "    chords = copy.deepcopy(fullMeasureChords)\n",
        "    measure.removeByNotOfClass([note.Note, note.Rest])\n",
        "    chords.removeByNotOfClass([chord.Chord])\n",
        "\n",
        "    # Information for the start of the measure.\n",
        "    # 1) measureStartTime: the offset for measure's start, e.g. 476.0.\n",
        "    # 2) measureStartOffset: how long from the measure start to the first element.\n",
        "    measureStartTime = measure[0].offset - (measure[0].offset % 4)\n",
        "    measureStartOffset  = measure[0].offset - measureStartTime\n",
        "\n",
        "    # Iterate over the notes and rests in measure, finding the grammar for each\n",
        "    # note in the measure and adding an abstract grammatical string for it. \n",
        "\n",
        "    fullGrammar = \"\"\n",
        "    prevNote = None # Store previous note. Need for interval.\n",
        "    numNonRests = 0 # Number of non-rest elements. Need for updating prevNote.\n",
        "    for ix, nr in enumerate(measure):\n",
        "        # Get the last chord. If no last chord, then (assuming chords is of length\n",
        "        # >0) shift first chord in chords to the beginning of the measure.\n",
        "        try: \n",
        "            lastChord = [n for n in chords if n.offset <= nr.offset][-1]\n",
        "        except IndexError:\n",
        "            chords[0].offset = measureStartTime\n",
        "            lastChord = [n for n in chords if n.offset <= nr.offset][-1]\n",
        "\n",
        "        # FIRST, get type of note, e.g. R for Rest, C for Chord, etc.\n",
        "        # Dealing with solo notes here. If unexpected chord: still call 'C'.\n",
        "        elementType = ' '\n",
        "        # R: First, check if it's a rest. Clearly a rest --> only one possibility.\n",
        "        if isinstance(nr, note.Rest):\n",
        "            elementType = 'R'\n",
        "        # C: Next, check to see if note pitch is in the last chord.\n",
        "        elif nr.name in lastChord.pitchNames or isinstance(nr, chord.Chord):\n",
        "            elementType = 'C'\n",
        "        # L: (Complement tone) Skip this for now.\n",
        "        # S: Check if it's a scale tone.\n",
        "        elif __is_scale_tone(lastChord, nr):\n",
        "            elementType = 'S'\n",
        "        # A: Check if it's an approach tone, i.e. +-1 halfstep chord tone.\n",
        "        elif __is_approach_tone(lastChord, nr):\n",
        "            elementType = 'A'\n",
        "        # X: Otherwise, it's an arbitrary tone. Generate random note.\n",
        "        else:\n",
        "            elementType = 'X'\n",
        "\n",
        "        # SECOND, get the length for each element. e.g. 8th note = R8, but\n",
        "        # to simplify things you'll use the direct num, e.g. R,0.125\n",
        "        if (ix == (len(measure)-1)):\n",
        "            # formula for a in \"a - b\": start of measure (e.g. 476) + 4\n",
        "            diff = measureStartTime + 4.0 - nr.offset\n",
        "        else:\n",
        "            diff = measure[ix + 1].offset - nr.offset\n",
        "\n",
        "        # Combine into the note info.\n",
        "        noteInfo = \"%s,%.3f\" % (elementType, nr.quarterLength) # back to diff\n",
        "\n",
        "        # THIRD, get the deltas (max range up, max range down) based on where\n",
        "        # the previous note was, +- minor 3. Skip rests (don't affect deltas).\n",
        "        intervalInfo = \"\"\n",
        "        if isinstance(nr, note.Note):\n",
        "            numNonRests += 1\n",
        "            if numNonRests == 1:\n",
        "                prevNote = nr\n",
        "            else:\n",
        "                noteDist = interval.Interval(noteStart=prevNote, noteEnd=nr)\n",
        "                noteDistUpper = interval.add([noteDist, \"m3\"])\n",
        "                noteDistLower = interval.subtract([noteDist, \"m3\"])\n",
        "                intervalInfo = \",<%s,%s>\" % (noteDistUpper.directedName, \n",
        "                    noteDistLower.directedName)\n",
        "                # print \"Upper, lower: %s, %s\" % (noteDistUpper,\n",
        "                #     noteDistLower)\n",
        "                # print \"Upper, lower dnames: %s, %s\" % (\n",
        "                #     noteDistUpper.directedName,\n",
        "                #     noteDistLower.directedName)\n",
        "                # print \"The interval: %s\" % (intervalInfo)\n",
        "                prevNote = nr\n",
        "\n",
        "        # Return. Do lazy evaluation for real-time performance.\n",
        "        grammarTerm = noteInfo + intervalInfo \n",
        "        fullGrammar += (grammarTerm + \" \")\n",
        "\n",
        "    return fullGrammar.rstrip()\n",
        "\n",
        "def __grouper(iterable, n, fillvalue=None):\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(*args, fillvalue=fillvalue)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FT57mTBFYMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prune_grammar(curr_grammar):\n",
        "    pruned_grammar = curr_grammar.split(' ')\n",
        "\n",
        "    for ix, gram in enumerate(pruned_grammar):\n",
        "        terms = gram.split(',')\n",
        "        terms[1] = str(__roundUpDown(float(terms[1]), 0.250, \n",
        "            random.choice([-1, 1])))\n",
        "        pruned_grammar[ix] = ','.join(terms)\n",
        "    pruned_grammar = ' '.join(pruned_grammar)\n",
        "\n",
        "    return pruned_grammar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM4sqkllFbnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prune_notes(curr_notes):\n",
        "    for n1, n2 in __grouper(curr_notes, n=2):\n",
        "        if n2 == None: # corner case: odd-length list\n",
        "            continue\n",
        "        if isinstance(n1, note.Note) and isinstance(n2, note.Note):\n",
        "            if n1.nameWithOctave == n2.nameWithOctave:\n",
        "                curr_notes.remove(n2)\n",
        "\n",
        "    return curr_notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE0OGHGOFepE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_notes(curr_notes):\n",
        "    removeIxs = []\n",
        "    for ix, m in enumerate(curr_notes):\n",
        "        # QA1: ensure nothing is of 0 quarter note len, if so changes its len\n",
        "        if (m.quarterLength == 0.0):\n",
        "            m.quarterLength = 0.250\n",
        "        # QA2: ensure no two melody notes have same offset, i.e. form a chord.\n",
        "        # Sorted, so same offset would be consecutive notes.\n",
        "        if (ix < (len(curr_notes) - 1)):\n",
        "            if (m.offset == curr_notes[ix + 1].offset and\n",
        "                isinstance(curr_notes[ix + 1], note.Note)):\n",
        "                removeIxs.append((ix + 1))\n",
        "    curr_notes = [i for ix, i in enumerate(curr_notes) if ix not in removeIxs]\n",
        "\n",
        "    return curr_notes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFYTv21xFzRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unparse_grammar(m1_grammar, m1_chords):\n",
        "    m1_elements = stream.Voice()\n",
        "    currOffset = 0.0 # for recalculate last chord.\n",
        "    prevElement = None\n",
        "    for ix, grammarElement in enumerate(m1_grammar.split(' ')):\n",
        "        terms = grammarElement.split(',')\n",
        "        currOffset += float(terms[1]) # works just fine\n",
        "\n",
        "        # Case 1: it's a rest. Just append\n",
        "        if terms[0] == 'R':\n",
        "            rNote = note.Rest(quarterLength = float(terms[1]))\n",
        "            m1_elements.insert(currOffset, rNote)\n",
        "            continue\n",
        "\n",
        "        # Get the last chord first so you can find chord note, scale note, etc.\n",
        "        try: \n",
        "            lastChord = [n for n in m1_chords if n.offset <= currOffset][-1]\n",
        "        except IndexError:\n",
        "            m1_chords[0].offset = 0.0\n",
        "            lastChord = [n for n in m1_chords if n.offset <= currOffset][-1]\n",
        "\n",
        "        # Case: no < > (should just be the first note) so generate from range\n",
        "        # of lowest chord note to highest chord note (if not a chord note, else\n",
        "        # just generate one of the actual chord notes). \n",
        "\n",
        "        # Case #1: if no < > to indicate next note range. Usually this lack of < >\n",
        "        # is for the first note (no precedent), or for rests.\n",
        "        if (len(terms) == 2): # Case 1: if no < >.\n",
        "            insertNote = note.Note() # default is C\n",
        "\n",
        "            # Case C: chord note.\n",
        "            if terms[0] == 'C':\n",
        "                insertNote = __generate_chord_tone(lastChord)\n",
        "\n",
        "            # Case S: scale note.\n",
        "            elif terms[0] == 'S':\n",
        "                insertNote = __generate_scale_tone(lastChord)\n",
        "\n",
        "            # Case A: approach note.\n",
        "            # Handle both A and X notes here for now.\n",
        "            else:\n",
        "                insertNote = __generate_approach_tone(lastChord)\n",
        "\n",
        "            # Update the stream of generated notes\n",
        "            insertNote.quarterLength = float(terms[1])\n",
        "            if insertNote.octave < 4:\n",
        "                insertNote.octave = 4\n",
        "            m1_elements.insert(currOffset, insertNote)\n",
        "            prevElement = insertNote\n",
        "\n",
        "        # Case #2: if < > for the increment. Usually for notes after the first one.\n",
        "        else:\n",
        "            # Get lower, upper intervals and notes.\n",
        "            interval1 = interval.Interval(terms[2].replace(\"<\",''))\n",
        "            interval2 = interval.Interval(terms[3].replace(\">\",''))\n",
        "            if interval1.cents > interval2.cents:\n",
        "                upperInterval, lowerInterval = interval1, interval2\n",
        "            else:\n",
        "                upperInterval, lowerInterval = interval2, interval1\n",
        "            lowPitch = interval.transposePitch(prevElement.pitch, lowerInterval)\n",
        "            highPitch = interval.transposePitch(prevElement.pitch, upperInterval)\n",
        "            numNotes = int(highPitch.ps - lowPitch.ps + 1) # for range(s, e)\n",
        "\n",
        "            # Case C: chord note, must be within increment (terms[2]).\n",
        "            # First, transpose note with lowerInterval to get note that is\n",
        "            # the lower bound. Then iterate over, and find valid notes. Then\n",
        "            # choose randomly from those.\n",
        "            \n",
        "            if terms[0] == 'C':\n",
        "                relevantChordTones = []\n",
        "                for i in range(0, numNotes):\n",
        "                    currNote = note.Note(lowPitch.transpose(i).simplifyEnharmonic())\n",
        "                    if __is_chord_tone(lastChord, currNote):\n",
        "                        relevantChordTones.append(currNote)\n",
        "                if len(relevantChordTones) > 1:\n",
        "                    insertNote = random.choice([i for i in relevantChordTones\n",
        "                        if i.nameWithOctave != prevElement.nameWithOctave])\n",
        "                elif len(relevantChordTones) == 1:\n",
        "                    insertNote = relevantChordTones[0]\n",
        "                else: # if no choices, set to prev element +-1 whole step\n",
        "                    insertNote = prevElement.transpose(random.choice([-2,2]))\n",
        "                if insertNote.octave < 3:\n",
        "                    insertNote.octave = 3\n",
        "                insertNote.quarterLength = float(terms[1])\n",
        "                m1_elements.insert(currOffset, insertNote)\n",
        "\n",
        "            # Case S: scale note, must be within increment.\n",
        "            elif terms[0] == 'S':\n",
        "                relevantScaleTones = []\n",
        "                for i in range(0, numNotes):\n",
        "                    currNote = note.Note(lowPitch.transpose(i).simplifyEnharmonic())\n",
        "                    if __is_scale_tone(lastChord, currNote):\n",
        "                        relevantScaleTones.append(currNote)\n",
        "                if len(relevantScaleTones) > 1:\n",
        "                    insertNote = random.choice([i for i in relevantScaleTones\n",
        "                        if i.nameWithOctave != prevElement.nameWithOctave])\n",
        "                elif len(relevantScaleTones) == 1:\n",
        "                    insertNote = relevantScaleTones[0]\n",
        "                else: # if no choices, set to prev element +-1 whole step\n",
        "                    insertNote = prevElement.transpose(random.choice([-2,2]))\n",
        "                if insertNote.octave < 3:\n",
        "                    insertNote.octave = 3\n",
        "                insertNote.quarterLength = float(terms[1])\n",
        "                m1_elements.insert(currOffset, insertNote)\n",
        "\n",
        "            # Case A: approach tone, must be within increment.\n",
        "            # For now: handle both A and X cases.\n",
        "            else:\n",
        "                relevantApproachTones = []\n",
        "                for i in range(0, numNotes):\n",
        "                    currNote = note.Note(lowPitch.transpose(i).simplifyEnharmonic())\n",
        "                    if __is_approach_tone(lastChord, currNote):\n",
        "                        relevantApproachTones.append(currNote)\n",
        "                if len(relevantApproachTones) > 1:\n",
        "                    insertNote = random.choice([i for i in relevantApproachTones\n",
        "                        if i.nameWithOctave != prevElement.nameWithOctave])\n",
        "                elif len(relevantApproachTones) == 1:\n",
        "                    insertNote = relevantApproachTones[0]\n",
        "                else: # if no choices, set to prev element +-1 whole step\n",
        "                    insertNote = prevElement.transpose(random.choice([-2,2]))\n",
        "                if insertNote.octave < 3:\n",
        "                    insertNote.octave = 3\n",
        "                insertNote.quarterLength = float(terms[1])\n",
        "                m1_elements.insert(currOffset, insertNote)\n",
        "\n",
        "            # update the previous element.\n",
        "            prevElement = insertNote\n",
        "\n",
        "    return m1_elements    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZnkapm-BpRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chords, abstract_grammars = get_musical_data('original_metheny.mid')\n",
        "corpus, tones, tones_indices, indices_tones = get_corpus_data(abstract_grammars)\n",
        "\n",
        "def post_processing(inference_model, corpus = corpus, abstract_grammars = abstract_grammars , tones = tones, tones_indices = tones_indices, indices_tones = indices_tones, T_y = 10, max_tries = 1000, diversity = 0.5):\n",
        "    \n",
        "    # set up audio stream\n",
        "    out_stream = stream.Stream()\n",
        "    \n",
        "    # Initialize chord variables\n",
        "    curr_offset = 0.0                                     # variable used to write sounds to the Stream.\n",
        "    num_chords = int(len(chords) / 3)                     # number of different set of chords\n",
        "    \n",
        "    print(\"Predicting new values for different set of chords.\")\n",
        "    # Loop over all 18 set of chords. At each iteration generate a sequence of tones\n",
        "    # and use the current chords to convert it into actual sounds \n",
        "    for i in range(1, num_chords):\n",
        "        \n",
        "        # Retrieve current chord from stream\n",
        "        curr_chords = stream.Voice()\n",
        "        \n",
        "        # Loop over the chords of the current set of chords\n",
        "        for j in chords[i]:\n",
        "            # Add chord to the current chords with the adequate offset, no need to understand this\n",
        "            curr_chords.insert((j.offset % 4), j)\n",
        "        \n",
        "        # Generate a sequence of tones using the model\n",
        "        _, indices = predict_and_sample(inference_model)\n",
        "        indices = list(indices.squeeze())\n",
        "        pred = [indices_tones[p] for p in indices]\n",
        "        \n",
        "        predicted_tones = 'C,0.25 '\n",
        "        for k in range(len(pred) - 1):\n",
        "            predicted_tones += pred[k] + ' ' \n",
        "        \n",
        "        predicted_tones +=  pred[-1]\n",
        "                \n",
        "        #### POST PROCESSING OF THE PREDICTED TONES ####\n",
        "        # We will consider \"A\" and \"X\" as \"C\" tones. It is a common choice.\n",
        "        predicted_tones = predicted_tones.replace(' A',' C').replace(' X',' C')\n",
        "\n",
        "        # Pruning #1: smoothing measure\n",
        "        predicted_tones = prune_grammar(predicted_tones)\n",
        "        \n",
        "        # Use predicted tones and current chords to generate sounds\n",
        "        sounds = unparse_grammar(predicted_tones, curr_chords)\n",
        "\n",
        "        # Pruning #2: removing repeated and too close together sounds\n",
        "        sounds = prune_notes(sounds)\n",
        "\n",
        "        # Quality assurance: clean up sounds\n",
        "        sounds = clean_up_notes(sounds)\n",
        "\n",
        "        # Print number of tones/notes in sounds\n",
        "        print('Generated %s sounds using the predicted values for the set of chords (\"%s\") and after pruning' % (len([k for k in sounds if isinstance(k, note.Note)]), i))\n",
        "        \n",
        "        # Insert sounds into the output stream\n",
        "        for m in sounds:\n",
        "            out_stream.insert(curr_offset + m.offset, m)\n",
        "        for mc in curr_chords:\n",
        "            out_stream.insert(curr_offset + mc.offset, mc)\n",
        "\n",
        "        curr_offset += 4.0\n",
        "        \n",
        "    # Initialize tempo of the output stream with 130 bit per minute\n",
        "    out_stream.insert(0.0, tempo.MetronomeMark(number=130))\n",
        "\n",
        "    # Save audio stream to fine\n",
        "    mf = midi.translate.streamToMidiFile(out_stream)\n",
        "    mf.open(\"new_music.midi\", 'wb')\n",
        "    mf.write()\n",
        "    print(\"Your generated music is saved in new_music.midi\")\n",
        "    mf.close()\n",
        "    \n",
        "    return out_stream"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k4TY7W4-kkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generate_Music():\n",
        "\n",
        "  inference_model = Music_Generation_Helper(notes = 78)\n",
        "  music = post_processing(inference_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJYXY_4jBR2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b8723655-321f-4142-dec7-271612682094"
      },
      "source": [
        "Generate_Music()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting new values for different set of chords.\n",
            "Generated 21 sounds using the predicted values for the set of chords (\"1\") and after pruning\n",
            "Generated 21 sounds using the predicted values for the set of chords (\"2\") and after pruning\n",
            "Generated 21 sounds using the predicted values for the set of chords (\"3\") and after pruning\n",
            "Generated 21 sounds using the predicted values for the set of chords (\"4\") and after pruning\n",
            "Generated 21 sounds using the predicted values for the set of chords (\"5\") and after pruning\n",
            "Your generated music is saved in new_music.midi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gSCXeuDEhuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}